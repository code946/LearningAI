过拟合--->正则化--->添加惩罚项--->防止系数过大

损失函数减小-->欧米伽函数的值要减小-->\theta要小

无论是L1还是L2，正则化力度越大，会放大惩罚项的值
让曲线更平滑

L1：随着alpha值的增大，系数大部分为0
L2：随着alpha值的增大，系数会减小，基本不为0

L1正则化适用于特征之间有关联的情况，经过L1正则化后，系数更容易趋近于0，部分特征值会被忽略掉，起到了特征选择的作用

特征关联：
数据集代表的是考试成绩
特征值：语文 数学 英语 总分
目标值：评价（>270 优秀，>240良好）

L2正则化：更适用于特征之间没有关联的情况（优先考虑）


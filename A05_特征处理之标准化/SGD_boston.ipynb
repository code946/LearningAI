{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 《按图索骥学机器学习》-《A05特征处理之标准化》"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这是《按图索骥学机器学习》-《A05特征处理之标准化》的讲义\n",
    "这门课程之所以叫按图索骥，是因为学习资料都放到了思维导图当中，大家可以根据自己的情况，选择合适的学习路径，自主学习\n",
    "\n",
    "![avatar](pic/swnt.png)\n",
    "\n",
    "导图和有关学习资料都放在了github(git.code946.com)上，并且在不断迭代和更新中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "lb= load_boston()\n",
    "\n",
    "print(lb[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(lb.data,lb.target,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看训练集和测试集的平均值，标准差是否一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.56275863356814\n",
      "137.69034899997743\n",
      "145.1555388220164\n",
      "70.92853130099452\n",
      "67.52373198061781\n",
      "70.07396704469443\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.std(x_train))\n",
    "print(np.std(x_test))\n",
    "print(np.std(lb.data))\n",
    "\n",
    "print(np.mean(x_train))\n",
    "print(np.mean(x_test))\n",
    "print(np.mean(lb.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先做数据分割，再分别对训练集和测试集进行标准化\n",
    "原因：如果你先对整体数据进行标准化，再分割成训练集和测试集，会导致训练集中包含了测试集的一些信息\n",
    "    影响测试集对模型评价的准确度\n",
    "    比方说：测试过程就是高考，测试集数据就是高考题\n",
    "         学校的模拟题相当于训练集数据，如果训练集中包含了测试集的信息\n",
    "         相当于模拟题中有高考题的出现，这回影响到最终的成绩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit_transform 与 transform区别\n",
    "\n",
    "fit_transform：两个步骤\n",
    "    fit : 计算中间值：求平均值和标准差，将结果保存到StandardScaler对象中\n",
    "    transform ：计算标砖化，得到标准化后的最终结果\n",
    "\n",
    "测试集中的特征值计算标准化的时候，使用的是训练集中的平均值和标准差\n",
    "理想中的测试集中的数据分布和训练集的数据分布式一致的，那么平均值和标准差也是差不多的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.54999749 -0.32886307 -0.41468882 -0.42509795 -0.41820031 -0.42386026\n",
      " -0.2779778   0.47209401 -0.38403796 -0.42348634]\n",
      "[ 1.42333897  0.1023422  -0.78024515 -1.13789493 -0.82639351 -0.71102262\n",
      " -0.09378832  1.42333897 -0.64756862 -0.71102262]\n",
      "[-1.03194466 -0.73674568  0.07505153  0.6127354   1.69864595  0.71816361\n",
      "  2.88998472 -0.92651645  0.67599232  0.06450871]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_x = StandardScaler()\n",
    "x_train = std_x.fit_transform(x_train)\n",
    "x_test = std_x.transform(x_test)\n",
    "\n",
    "std_y = StandardScaler()\n",
    "y_train = std_y.fit_transform(y_train.reshape(-1,1))\n",
    "y_test = std_y.transform(y_test.reshape(-1,1))\n",
    "\n",
    "print(x_train[:10,0])\n",
    "print(x_train[:10,9])\n",
    "print(y_train[:10,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.linear_model.SGDRegressor(loss=’squared_loss’, penalty=’l2’, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, random_state=None, learning_rate=’invscaling’, eta0=0.01, power_t=0.25, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, warm_start=False, average=False)\n",
    "\n",
    "learning_rate=’invscaling’: sk-learn内置的一套参数取值方案\n",
    "eta0代表的是学习率\n",
    "\n",
    "梯度下降结束运行的条件：\n",
    "1、 max_iter:代表的是最大的迭代次数\n",
    "\n",
    "2、当前的损失值 - 上一次损失值 < epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "             eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "             learning_rate='invscaling', loss='squared_loss', max_iter=1000,\n",
       "             n_iter_no_change=5, penalty='l2', power_t=0.25, random_state=None,\n",
       "             shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd = SGDRegressor()\n",
    "sgd.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测价格：27.824319\n"
     ]
    }
   ],
   "source": [
    "y_predict = std_y.inverse_transform(sgd.predict(x_test))\n",
    "# 输出预测结果时，要对数值进行标准化的逆运算 \n",
    "\n",
    "print(\"预测价格：%f\" % y_predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均方误差：15.822986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"均方误差：%f\" % mean_squared_error(std_y.inverse_transform(y_test),y_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
